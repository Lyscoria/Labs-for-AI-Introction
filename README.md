# 人工智能引论（2025春） Labs

这是北京某大学 2025 年春《人工智能引论》的课程 Labs。总共有 5 个 Lab，分别是：

0. Python 基础
1. 搜索
2. 机器学习
3. 自然语言处理
4. 机器人与仿真

本人菜菜的，Lab 做起来还是挺费时费力的，得分分别是：`12/12(Lab1-Part1)`，`9.2/12(Lab1-Part2)`，`19.6/20(Lab2)`，`20/20(Lab3)`，`20/20(Lab4)`。

Lab1-Part1 是最简单的部分，只需要实现几个经典的搜索算法，包括DFS，UCS，A*。Lab1-Part2 是实现 Minimax 搜索，Alpha-Beta 剪枝和 MCTS，实现完还是比较有成就感的，但是 MCTS 的本地评测分数与实际分数出现了非常大的差异，问题大概是出在 `Simulation` 过程的得分设置上。如果按照经典（也是课上讲的）赢 1 输 0 的方式计分，会产生奇特的结果：`Backproagation` 过程按理来说应当更新搜索树的全部节点，但如果更新根节点，会导致吃豆人变得非常傻，输掉好几个测试用例；不更新根节点反而分数很高。于是就没有更新根节点，从最终结果来看这样无法通过很多新的测试用例。实际上从大家的情况来看就没有人在 Lab1-Part2 上满分或很接近满分，测试用例也完全不公开，就无从得知到底什么是真正正确的实现。

Lab2 是调参的开始。这里需要实现基本的梯度下降过程（包括前向和反向传播），在此基础上实现逻辑回归，分类树，随机森林等。写这一部分之前最好先弄清楚反向传播的矩阵计算形式，感觉和课上讲的有一些出入（其实我也确实没好好听课qwq）。感觉 Lab2 是调参最痛苦的部分，但调好参数之后最后得分还是挺好的。我没有打算去卷 Question 4 ，只是用 MLP 调了调参，幸运地发现了一组比较好的超参数（？），不晓得像 `README` 说的自己实现卷积算子效果如何。

Lab3 是自然语言处理，Part2 目的是让大家练习给 Deepseek 写提示词的能力（？）本地满分就是满分。Part1 涉及朴素贝叶斯分类，神经网络分类和 TF-IDF，特别地，TF-IDF 的部分并没有明确给出应该如何利用 TF 和 IDF 对进行排序，但是在那两个 CS50 的链接里有详细要求，不晓得课程组为什么不在 `README` 里说明。

Lab4 就是运动定位，运动控制和运动规划。这一部分的调参非常离谱，感觉调出来的参数完全没有泛化性，稍微动一点就是好几十分的差距。`Resample` 过程中提到了加权平均和轮盘赌两种重采样方式，据说轮盘赌是实践中更常见的做法，但是效果奇差，远不如直接加权平均。最终本地评测分数就是实际分数，无法想象如果加了新测试用例之后训练出来的模型表现是个啥样。

总的来说，我因为看树洞上 2024 秋的测评中“学 AI 引论能比 AI 基础学到更多东西”，“改革后的 AI 引论也不失为一门好课”选了这门课，实际上确实学到了很多，但是无论是授课质量还是最终给分上都令人不甚满意 TAT， 风评远不如 AI 基础。真心希望 PKU 的课程建设能越来越好，让每个人的努力都能得到回报 qwq。